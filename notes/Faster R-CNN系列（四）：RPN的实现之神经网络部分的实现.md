
# RPN的实现之神经网络部分的实现
RPN的框架：
![rpn_framework.png](images/rpn_framework.png)
* 图解
    * 上支路是所有anchor的修正量（4\*9）
    * 下支路是前景背景9个anchor的分类得分(前景 背景)

* rpn_match
    * label为1的anchor： 当一个anchor与真实bounding box的最大IOU超过阈值Vt1(0.7)
    * label为-1的anchor ： 当一个anchor与真实bounding box的最大IOU低于阈值Vt2(0.3)
    * label为0的anchor ： 当一个anchor与真实bounding box的最大IOU介于Vt2与Vt1之间
    * Negative anchor 与 Positive anchor 的数量之和是一个人为设置的常数

* rpn_bbox
    * Input_rpn_bbox 是anchor和真实bbox之间的偏移量，RPN网络计算的也是偏移量!
    * 只有positive anchor才有对应的Input_rpn_bbox 

ResNet
* block
    * 保证跳远连接层和最后一层输入层的长宽以及通道数一样，可以实现相加操作
      ![resnet.png](images/resnet_block.png)
* 架构
    ![resnet_framework.png](images/resnet_framework.png)


```python
import keras.layers as KL
from keras.models import Model
import keras.backend as K
import tensorflow as tf
```

构建block


```python
def building_block(filters,block):
    if block !=0 :
        stride=1
    else:
        stride=2
    
    def f(x):
        # 主通路
        y=KL.Conv2D(filters,(1,1),strides=stride)(x)
        y=KL.BatchNormalization(axis=3)(y)
        y=KL.Activation("relu")(y)
        
        y=KL.Conv2D(filters,(3,3),padding="same")(y)
        y=KL.BatchNormalization(axis=3)(y)
        y=KL.Activation("relu")(y)
        
        y=KL.Conv2D(4*filters,(1,1))(y)
        y=KL.BatchNormalization(axis=3)(y)
        
        
        if block==0 :
            shortcut=KL.Conv2D(4*filters,(1,1),strides=stride)(x)
            shortcut=KL.BatchNormalization(axis=3)(shortcut)
        else:
            shortcut=x
            
        y=KL.Add()([y,shortcut])
        y=KL.Activation("relu")(y)
        
        return y
    return f
```

构建resnet


```python
def resNet_featureExtractor(inputs):
    x=KL.Conv2D(64,(3,3),padding="same")(inputs)
    x=KL.BatchNormalization(axis=3)(x)
    x=KL.Activation("relu")(x)
    
    filters=64
    
    # 每一个stage的block的个数  每个stage中 第一个block是block1 其他的是block2
    blocks=[3,6,4]
    
    for i,block_num in enumerate(blocks):
        for block_id in range(block_num):
            x=building_block(filters,block_id)(x)
        filters *=2
    return x
        
```


```python
x=KL.Input((64,64,3))
y=resNet_featureExtractor(x)
model=Model([x],[y])
model.summary()
```

    __________________________________________________________________________________________________
    Layer (type)                    Output Shape         Param #     Connected to                     
    ==================================================================================================
    input_2 (InputLayer)            (None, 64, 64, 3)    0                                            
    __________________________________________________________________________________________________
    conv2d_44 (Conv2D)              (None, 64, 64, 64)   1792        input_2[0][0]                    
    __________________________________________________________________________________________________
    batch_normalization_44 (BatchNo (None, 64, 64, 64)   256         conv2d_44[0][0]                  
    __________________________________________________________________________________________________
    activation_41 (Activation)      (None, 64, 64, 64)   0           batch_normalization_44[0][0]     
    __________________________________________________________________________________________________
    conv2d_45 (Conv2D)              (None, 32, 32, 64)   4160        activation_41[0][0]              
    __________________________________________________________________________________________________
    batch_normalization_45 (BatchNo (None, 32, 32, 64)   256         conv2d_45[0][0]                  
    __________________________________________________________________________________________________
    activation_42 (Activation)      (None, 32, 32, 64)   0           batch_normalization_45[0][0]     
    __________________________________________________________________________________________________
    conv2d_46 (Conv2D)              (None, 32, 32, 64)   36928       activation_42[0][0]              
    __________________________________________________________________________________________________
    batch_normalization_46 (BatchNo (None, 32, 32, 64)   256         conv2d_46[0][0]                  
    __________________________________________________________________________________________________
    activation_43 (Activation)      (None, 32, 32, 64)   0           batch_normalization_46[0][0]     
    __________________________________________________________________________________________________
    conv2d_47 (Conv2D)              (None, 32, 32, 256)  16640       activation_43[0][0]              
    __________________________________________________________________________________________________
    conv2d_48 (Conv2D)              (None, 32, 32, 256)  16640       activation_41[0][0]              
    __________________________________________________________________________________________________
    batch_normalization_47 (BatchNo (None, 32, 32, 256)  1024        conv2d_47[0][0]                  
    __________________________________________________________________________________________________
    batch_normalization_48 (BatchNo (None, 32, 32, 256)  1024        conv2d_48[0][0]                  
    __________________________________________________________________________________________________
    add_14 (Add)                    (None, 32, 32, 256)  0           batch_normalization_47[0][0]     
                                                                     batch_normalization_48[0][0]     
    __________________________________________________________________________________________________
    activation_44 (Activation)      (None, 32, 32, 256)  0           add_14[0][0]                     
    __________________________________________________________________________________________________
    conv2d_49 (Conv2D)              (None, 32, 32, 64)   16448       activation_44[0][0]              
    __________________________________________________________________________________________________
    batch_normalization_49 (BatchNo (None, 32, 32, 64)   256         conv2d_49[0][0]                  
    __________________________________________________________________________________________________
    activation_45 (Activation)      (None, 32, 32, 64)   0           batch_normalization_49[0][0]     
    __________________________________________________________________________________________________
    conv2d_50 (Conv2D)              (None, 32, 32, 64)   36928       activation_45[0][0]              
    __________________________________________________________________________________________________
    batch_normalization_50 (BatchNo (None, 32, 32, 64)   256         conv2d_50[0][0]                  
    __________________________________________________________________________________________________
    activation_46 (Activation)      (None, 32, 32, 64)   0           batch_normalization_50[0][0]     
    __________________________________________________________________________________________________
    conv2d_51 (Conv2D)              (None, 32, 32, 256)  16640       activation_46[0][0]              
    __________________________________________________________________________________________________
    batch_normalization_51 (BatchNo (None, 32, 32, 256)  1024        conv2d_51[0][0]                  
    __________________________________________________________________________________________________
    add_15 (Add)                    (None, 32, 32, 256)  0           batch_normalization_51[0][0]     
                                                                     activation_44[0][0]              
    __________________________________________________________________________________________________
    activation_47 (Activation)      (None, 32, 32, 256)  0           add_15[0][0]                     
    __________________________________________________________________________________________________
    conv2d_52 (Conv2D)              (None, 32, 32, 64)   16448       activation_47[0][0]              
    __________________________________________________________________________________________________
    batch_normalization_52 (BatchNo (None, 32, 32, 64)   256         conv2d_52[0][0]                  
    __________________________________________________________________________________________________
    activation_48 (Activation)      (None, 32, 32, 64)   0           batch_normalization_52[0][0]     
    __________________________________________________________________________________________________
    conv2d_53 (Conv2D)              (None, 32, 32, 64)   36928       activation_48[0][0]              
    __________________________________________________________________________________________________
    batch_normalization_53 (BatchNo (None, 32, 32, 64)   256         conv2d_53[0][0]                  
    __________________________________________________________________________________________________
    activation_49 (Activation)      (None, 32, 32, 64)   0           batch_normalization_53[0][0]     
    __________________________________________________________________________________________________
    conv2d_54 (Conv2D)              (None, 32, 32, 256)  16640       activation_49[0][0]              
    __________________________________________________________________________________________________
    batch_normalization_54 (BatchNo (None, 32, 32, 256)  1024        conv2d_54[0][0]                  
    __________________________________________________________________________________________________
    add_16 (Add)                    (None, 32, 32, 256)  0           batch_normalization_54[0][0]     
                                                                     activation_47[0][0]              
    __________________________________________________________________________________________________
    activation_50 (Activation)      (None, 32, 32, 256)  0           add_16[0][0]                     
    __________________________________________________________________________________________________
    conv2d_55 (Conv2D)              (None, 16, 16, 128)  32896       activation_50[0][0]              
    __________________________________________________________________________________________________
    batch_normalization_55 (BatchNo (None, 16, 16, 128)  512         conv2d_55[0][0]                  
    __________________________________________________________________________________________________
    activation_51 (Activation)      (None, 16, 16, 128)  0           batch_normalization_55[0][0]     
    __________________________________________________________________________________________________
    conv2d_56 (Conv2D)              (None, 16, 16, 128)  147584      activation_51[0][0]              
    __________________________________________________________________________________________________
    batch_normalization_56 (BatchNo (None, 16, 16, 128)  512         conv2d_56[0][0]                  
    __________________________________________________________________________________________________
    activation_52 (Activation)      (None, 16, 16, 128)  0           batch_normalization_56[0][0]     
    __________________________________________________________________________________________________
    conv2d_57 (Conv2D)              (None, 16, 16, 512)  66048       activation_52[0][0]              
    __________________________________________________________________________________________________
    conv2d_58 (Conv2D)              (None, 16, 16, 512)  131584      activation_50[0][0]              
    __________________________________________________________________________________________________
    batch_normalization_57 (BatchNo (None, 16, 16, 512)  2048        conv2d_57[0][0]                  
    __________________________________________________________________________________________________
    batch_normalization_58 (BatchNo (None, 16, 16, 512)  2048        conv2d_58[0][0]                  
    __________________________________________________________________________________________________
    add_17 (Add)                    (None, 16, 16, 512)  0           batch_normalization_57[0][0]     
                                                                     batch_normalization_58[0][0]     
    __________________________________________________________________________________________________
    activation_53 (Activation)      (None, 16, 16, 512)  0           add_17[0][0]                     
    __________________________________________________________________________________________________
    conv2d_59 (Conv2D)              (None, 16, 16, 128)  65664       activation_53[0][0]              
    __________________________________________________________________________________________________
    batch_normalization_59 (BatchNo (None, 16, 16, 128)  512         conv2d_59[0][0]                  
    __________________________________________________________________________________________________
    activation_54 (Activation)      (None, 16, 16, 128)  0           batch_normalization_59[0][0]     
    __________________________________________________________________________________________________
    conv2d_60 (Conv2D)              (None, 16, 16, 128)  147584      activation_54[0][0]              
    __________________________________________________________________________________________________
    batch_normalization_60 (BatchNo (None, 16, 16, 128)  512         conv2d_60[0][0]                  
    __________________________________________________________________________________________________
    activation_55 (Activation)      (None, 16, 16, 128)  0           batch_normalization_60[0][0]     
    __________________________________________________________________________________________________
    conv2d_61 (Conv2D)              (None, 16, 16, 512)  66048       activation_55[0][0]              
    __________________________________________________________________________________________________
    batch_normalization_61 (BatchNo (None, 16, 16, 512)  2048        conv2d_61[0][0]                  
    __________________________________________________________________________________________________
    add_18 (Add)                    (None, 16, 16, 512)  0           batch_normalization_61[0][0]     
                                                                     activation_53[0][0]              
    __________________________________________________________________________________________________
    activation_56 (Activation)      (None, 16, 16, 512)  0           add_18[0][0]                     
    __________________________________________________________________________________________________
    conv2d_62 (Conv2D)              (None, 16, 16, 128)  65664       activation_56[0][0]              
    __________________________________________________________________________________________________
    batch_normalization_62 (BatchNo (None, 16, 16, 128)  512         conv2d_62[0][0]                  
    __________________________________________________________________________________________________
    activation_57 (Activation)      (None, 16, 16, 128)  0           batch_normalization_62[0][0]     
    __________________________________________________________________________________________________
    conv2d_63 (Conv2D)              (None, 16, 16, 128)  147584      activation_57[0][0]              
    __________________________________________________________________________________________________
    batch_normalization_63 (BatchNo (None, 16, 16, 128)  512         conv2d_63[0][0]                  
    __________________________________________________________________________________________________
    activation_58 (Activation)      (None, 16, 16, 128)  0           batch_normalization_63[0][0]     
    __________________________________________________________________________________________________
    conv2d_64 (Conv2D)              (None, 16, 16, 512)  66048       activation_58[0][0]              
    __________________________________________________________________________________________________
    batch_normalization_64 (BatchNo (None, 16, 16, 512)  2048        conv2d_64[0][0]                  
    __________________________________________________________________________________________________
    add_19 (Add)                    (None, 16, 16, 512)  0           batch_normalization_64[0][0]     
                                                                     activation_56[0][0]              
    __________________________________________________________________________________________________
    activation_59 (Activation)      (None, 16, 16, 512)  0           add_19[0][0]                     
    __________________________________________________________________________________________________
    conv2d_65 (Conv2D)              (None, 16, 16, 128)  65664       activation_59[0][0]              
    __________________________________________________________________________________________________
    batch_normalization_65 (BatchNo (None, 16, 16, 128)  512         conv2d_65[0][0]                  
    __________________________________________________________________________________________________
    activation_60 (Activation)      (None, 16, 16, 128)  0           batch_normalization_65[0][0]     
    __________________________________________________________________________________________________
    conv2d_66 (Conv2D)              (None, 16, 16, 128)  147584      activation_60[0][0]              
    __________________________________________________________________________________________________
    batch_normalization_66 (BatchNo (None, 16, 16, 128)  512         conv2d_66[0][0]                  
    __________________________________________________________________________________________________
    activation_61 (Activation)      (None, 16, 16, 128)  0           batch_normalization_66[0][0]     
    __________________________________________________________________________________________________
    conv2d_67 (Conv2D)              (None, 16, 16, 512)  66048       activation_61[0][0]              
    __________________________________________________________________________________________________
    batch_normalization_67 (BatchNo (None, 16, 16, 512)  2048        conv2d_67[0][0]                  
    __________________________________________________________________________________________________
    add_20 (Add)                    (None, 16, 16, 512)  0           batch_normalization_67[0][0]     
                                                                     activation_59[0][0]              
    __________________________________________________________________________________________________
    activation_62 (Activation)      (None, 16, 16, 512)  0           add_20[0][0]                     
    __________________________________________________________________________________________________
    conv2d_68 (Conv2D)              (None, 16, 16, 128)  65664       activation_62[0][0]              
    __________________________________________________________________________________________________
    batch_normalization_68 (BatchNo (None, 16, 16, 128)  512         conv2d_68[0][0]                  
    __________________________________________________________________________________________________
    activation_63 (Activation)      (None, 16, 16, 128)  0           batch_normalization_68[0][0]     
    __________________________________________________________________________________________________
    conv2d_69 (Conv2D)              (None, 16, 16, 128)  147584      activation_63[0][0]              
    __________________________________________________________________________________________________
    batch_normalization_69 (BatchNo (None, 16, 16, 128)  512         conv2d_69[0][0]                  
    __________________________________________________________________________________________________
    activation_64 (Activation)      (None, 16, 16, 128)  0           batch_normalization_69[0][0]     
    __________________________________________________________________________________________________
    conv2d_70 (Conv2D)              (None, 16, 16, 512)  66048       activation_64[0][0]              
    __________________________________________________________________________________________________
    batch_normalization_70 (BatchNo (None, 16, 16, 512)  2048        conv2d_70[0][0]                  
    __________________________________________________________________________________________________
    add_21 (Add)                    (None, 16, 16, 512)  0           batch_normalization_70[0][0]     
                                                                     activation_62[0][0]              
    __________________________________________________________________________________________________
    activation_65 (Activation)      (None, 16, 16, 512)  0           add_21[0][0]                     
    __________________________________________________________________________________________________
    conv2d_71 (Conv2D)              (None, 16, 16, 128)  65664       activation_65[0][0]              
    __________________________________________________________________________________________________
    batch_normalization_71 (BatchNo (None, 16, 16, 128)  512         conv2d_71[0][0]                  
    __________________________________________________________________________________________________
    activation_66 (Activation)      (None, 16, 16, 128)  0           batch_normalization_71[0][0]     
    __________________________________________________________________________________________________
    conv2d_72 (Conv2D)              (None, 16, 16, 128)  147584      activation_66[0][0]              
    __________________________________________________________________________________________________
    batch_normalization_72 (BatchNo (None, 16, 16, 128)  512         conv2d_72[0][0]                  
    __________________________________________________________________________________________________
    activation_67 (Activation)      (None, 16, 16, 128)  0           batch_normalization_72[0][0]     
    __________________________________________________________________________________________________
    conv2d_73 (Conv2D)              (None, 16, 16, 512)  66048       activation_67[0][0]              
    __________________________________________________________________________________________________
    batch_normalization_73 (BatchNo (None, 16, 16, 512)  2048        conv2d_73[0][0]                  
    __________________________________________________________________________________________________
    add_22 (Add)                    (None, 16, 16, 512)  0           batch_normalization_73[0][0]     
                                                                     activation_65[0][0]              
    __________________________________________________________________________________________________
    activation_68 (Activation)      (None, 16, 16, 512)  0           add_22[0][0]                     
    __________________________________________________________________________________________________
    conv2d_74 (Conv2D)              (None, 8, 8, 256)    131328      activation_68[0][0]              
    __________________________________________________________________________________________________
    batch_normalization_74 (BatchNo (None, 8, 8, 256)    1024        conv2d_74[0][0]                  
    __________________________________________________________________________________________________
    activation_69 (Activation)      (None, 8, 8, 256)    0           batch_normalization_74[0][0]     
    __________________________________________________________________________________________________
    conv2d_75 (Conv2D)              (None, 8, 8, 256)    590080      activation_69[0][0]              
    __________________________________________________________________________________________________
    batch_normalization_75 (BatchNo (None, 8, 8, 256)    1024        conv2d_75[0][0]                  
    __________________________________________________________________________________________________
    activation_70 (Activation)      (None, 8, 8, 256)    0           batch_normalization_75[0][0]     
    __________________________________________________________________________________________________
    conv2d_76 (Conv2D)              (None, 8, 8, 1024)   263168      activation_70[0][0]              
    __________________________________________________________________________________________________
    conv2d_77 (Conv2D)              (None, 8, 8, 1024)   525312      activation_68[0][0]              
    __________________________________________________________________________________________________
    batch_normalization_76 (BatchNo (None, 8, 8, 1024)   4096        conv2d_76[0][0]                  
    __________________________________________________________________________________________________
    batch_normalization_77 (BatchNo (None, 8, 8, 1024)   4096        conv2d_77[0][0]                  
    __________________________________________________________________________________________________
    add_23 (Add)                    (None, 8, 8, 1024)   0           batch_normalization_76[0][0]     
                                                                     batch_normalization_77[0][0]     
    __________________________________________________________________________________________________
    activation_71 (Activation)      (None, 8, 8, 1024)   0           add_23[0][0]                     
    __________________________________________________________________________________________________
    conv2d_78 (Conv2D)              (None, 8, 8, 256)    262400      activation_71[0][0]              
    __________________________________________________________________________________________________
    batch_normalization_78 (BatchNo (None, 8, 8, 256)    1024        conv2d_78[0][0]                  
    __________________________________________________________________________________________________
    activation_72 (Activation)      (None, 8, 8, 256)    0           batch_normalization_78[0][0]     
    __________________________________________________________________________________________________
    conv2d_79 (Conv2D)              (None, 8, 8, 256)    590080      activation_72[0][0]              
    __________________________________________________________________________________________________
    batch_normalization_79 (BatchNo (None, 8, 8, 256)    1024        conv2d_79[0][0]                  
    __________________________________________________________________________________________________
    activation_73 (Activation)      (None, 8, 8, 256)    0           batch_normalization_79[0][0]     
    __________________________________________________________________________________________________
    conv2d_80 (Conv2D)              (None, 8, 8, 1024)   263168      activation_73[0][0]              
    __________________________________________________________________________________________________
    batch_normalization_80 (BatchNo (None, 8, 8, 1024)   4096        conv2d_80[0][0]                  
    __________________________________________________________________________________________________
    add_24 (Add)                    (None, 8, 8, 1024)   0           batch_normalization_80[0][0]     
                                                                     activation_71[0][0]              
    __________________________________________________________________________________________________
    activation_74 (Activation)      (None, 8, 8, 1024)   0           add_24[0][0]                     
    __________________________________________________________________________________________________
    conv2d_81 (Conv2D)              (None, 8, 8, 256)    262400      activation_74[0][0]              
    __________________________________________________________________________________________________
    batch_normalization_81 (BatchNo (None, 8, 8, 256)    1024        conv2d_81[0][0]                  
    __________________________________________________________________________________________________
    activation_75 (Activation)      (None, 8, 8, 256)    0           batch_normalization_81[0][0]     
    __________________________________________________________________________________________________
    conv2d_82 (Conv2D)              (None, 8, 8, 256)    590080      activation_75[0][0]              
    __________________________________________________________________________________________________
    batch_normalization_82 (BatchNo (None, 8, 8, 256)    1024        conv2d_82[0][0]                  
    __________________________________________________________________________________________________
    activation_76 (Activation)      (None, 8, 8, 256)    0           batch_normalization_82[0][0]     
    __________________________________________________________________________________________________
    conv2d_83 (Conv2D)              (None, 8, 8, 1024)   263168      activation_76[0][0]              
    __________________________________________________________________________________________________
    batch_normalization_83 (BatchNo (None, 8, 8, 1024)   4096        conv2d_83[0][0]                  
    __________________________________________________________________________________________________
    add_25 (Add)                    (None, 8, 8, 1024)   0           batch_normalization_83[0][0]     
                                                                     activation_74[0][0]              
    __________________________________________________________________________________________________
    activation_77 (Activation)      (None, 8, 8, 1024)   0           add_25[0][0]                     
    __________________________________________________________________________________________________
    conv2d_84 (Conv2D)              (None, 8, 8, 256)    262400      activation_77[0][0]              
    __________________________________________________________________________________________________
    batch_normalization_84 (BatchNo (None, 8, 8, 256)    1024        conv2d_84[0][0]                  
    __________________________________________________________________________________________________
    activation_78 (Activation)      (None, 8, 8, 256)    0           batch_normalization_84[0][0]     
    __________________________________________________________________________________________________
    conv2d_85 (Conv2D)              (None, 8, 8, 256)    590080      activation_78[0][0]              
    __________________________________________________________________________________________________
    batch_normalization_85 (BatchNo (None, 8, 8, 256)    1024        conv2d_85[0][0]                  
    __________________________________________________________________________________________________
    activation_79 (Activation)      (None, 8, 8, 256)    0           batch_normalization_85[0][0]     
    __________________________________________________________________________________________________
    conv2d_86 (Conv2D)              (None, 8, 8, 1024)   263168      activation_79[0][0]              
    __________________________________________________________________________________________________
    batch_normalization_86 (BatchNo (None, 8, 8, 1024)   4096        conv2d_86[0][0]                  
    __________________________________________________________________________________________________
    add_26 (Add)                    (None, 8, 8, 1024)   0           batch_normalization_86[0][0]     
                                                                     activation_77[0][0]              
    __________________________________________________________________________________________________
    activation_80 (Activation)      (None, 8, 8, 1024)   0           add_26[0][0]                     
    ==================================================================================================
    Total params: 6,902,656
    Trainable params: 6,875,136
    Non-trainable params: 27,520
    __________________________________________________________________________________________________



```python
from keras.utils.vis_utils import plot_model
plot_model(model,to_file="images/rpn_resnet_model.png",show_shapes=True)
```

![rpn_resnet_model.png](images/rpn_resnet_model.png)

CNN网络构建完成后，实现后续rpn


```python
def rpn_net(inputs,k):
    shared_map=KL.Conv2D(256,(3,3),padding="same")(inputs)
    shared_map=KL.Activation("linear")(shared_map)
    
    # 下支路
    rpn_class=KL.Conv2D(2*k,(1,1))(shared_map)
    rpn_class=KL.Lambda(lambda x:tf.reshape(x,[tf.shape(rpn_class)[0],-1,2]))(rpn_class)
    rpn_class=KL.Activation("linear")(rpn_class)
    rpn_prob=KL.Activation("softmax")(rpn_class)
    
    
    #上支路
    y=KL.Conv2D(4*k,(1,1))(shared_map)
    y=KL.Activation("linear")(y)
    rpn_bbox=KL.Lambda(lambda x:tf.reshape(x,[tf.shape(x)[0],-1,4]))(y)
    
    return rpn_class,rpn_prob,rpn_bbox
```


```python
x=KL.Input((64,64,3))
fp=resNet_featureExtractor(x)
rpn_class,rpn_prob,rpn_bbox=rpn_net(fp,9)
rpn_model=Model([x],[rpn_class,rpn_prob,rpn_bbox])
rpn_model.summary()
```

    __________________________________________________________________________________________________
    Layer (type)                    Output Shape         Param #     Connected to                     
    ==================================================================================================
    input_4 (InputLayer)            (None, 64, 64, 3)    0                                            
    __________________________________________________________________________________________________
    conv2d_132 (Conv2D)             (None, 64, 64, 64)   1792        input_4[0][0]                    
    __________________________________________________________________________________________________
    batch_normalization_130 (BatchN (None, 64, 64, 64)   256         conv2d_132[0][0]                 
    __________________________________________________________________________________________________
    activation_122 (Activation)     (None, 64, 64, 64)   0           batch_normalization_130[0][0]    
    __________________________________________________________________________________________________
    conv2d_133 (Conv2D)             (None, 32, 32, 64)   4160        activation_122[0][0]             
    __________________________________________________________________________________________________
    batch_normalization_131 (BatchN (None, 32, 32, 64)   256         conv2d_133[0][0]                 
    __________________________________________________________________________________________________
    activation_123 (Activation)     (None, 32, 32, 64)   0           batch_normalization_131[0][0]    
    __________________________________________________________________________________________________
    conv2d_134 (Conv2D)             (None, 32, 32, 64)   36928       activation_123[0][0]             
    __________________________________________________________________________________________________
    batch_normalization_132 (BatchN (None, 32, 32, 64)   256         conv2d_134[0][0]                 
    __________________________________________________________________________________________________
    activation_124 (Activation)     (None, 32, 32, 64)   0           batch_normalization_132[0][0]    
    __________________________________________________________________________________________________
    conv2d_135 (Conv2D)             (None, 32, 32, 256)  16640       activation_124[0][0]             
    __________________________________________________________________________________________________
    conv2d_136 (Conv2D)             (None, 32, 32, 256)  16640       activation_122[0][0]             
    __________________________________________________________________________________________________
    batch_normalization_133 (BatchN (None, 32, 32, 256)  1024        conv2d_135[0][0]                 
    __________________________________________________________________________________________________
    batch_normalization_134 (BatchN (None, 32, 32, 256)  1024        conv2d_136[0][0]                 
    __________________________________________________________________________________________________
    add_40 (Add)                    (None, 32, 32, 256)  0           batch_normalization_133[0][0]    
                                                                     batch_normalization_134[0][0]    
    __________________________________________________________________________________________________
    activation_125 (Activation)     (None, 32, 32, 256)  0           add_40[0][0]                     
    __________________________________________________________________________________________________
    conv2d_137 (Conv2D)             (None, 32, 32, 64)   16448       activation_125[0][0]             
    __________________________________________________________________________________________________
    batch_normalization_135 (BatchN (None, 32, 32, 64)   256         conv2d_137[0][0]                 
    __________________________________________________________________________________________________
    activation_126 (Activation)     (None, 32, 32, 64)   0           batch_normalization_135[0][0]    
    __________________________________________________________________________________________________
    conv2d_138 (Conv2D)             (None, 32, 32, 64)   36928       activation_126[0][0]             
    __________________________________________________________________________________________________
    batch_normalization_136 (BatchN (None, 32, 32, 64)   256         conv2d_138[0][0]                 
    __________________________________________________________________________________________________
    activation_127 (Activation)     (None, 32, 32, 64)   0           batch_normalization_136[0][0]    
    __________________________________________________________________________________________________
    conv2d_139 (Conv2D)             (None, 32, 32, 256)  16640       activation_127[0][0]             
    __________________________________________________________________________________________________
    batch_normalization_137 (BatchN (None, 32, 32, 256)  1024        conv2d_139[0][0]                 
    __________________________________________________________________________________________________
    add_41 (Add)                    (None, 32, 32, 256)  0           batch_normalization_137[0][0]    
                                                                     activation_125[0][0]             
    __________________________________________________________________________________________________
    activation_128 (Activation)     (None, 32, 32, 256)  0           add_41[0][0]                     
    __________________________________________________________________________________________________
    conv2d_140 (Conv2D)             (None, 32, 32, 64)   16448       activation_128[0][0]             
    __________________________________________________________________________________________________
    batch_normalization_138 (BatchN (None, 32, 32, 64)   256         conv2d_140[0][0]                 
    __________________________________________________________________________________________________
    activation_129 (Activation)     (None, 32, 32, 64)   0           batch_normalization_138[0][0]    
    __________________________________________________________________________________________________
    conv2d_141 (Conv2D)             (None, 32, 32, 64)   36928       activation_129[0][0]             
    __________________________________________________________________________________________________
    batch_normalization_139 (BatchN (None, 32, 32, 64)   256         conv2d_141[0][0]                 
    __________________________________________________________________________________________________
    activation_130 (Activation)     (None, 32, 32, 64)   0           batch_normalization_139[0][0]    
    __________________________________________________________________________________________________
    conv2d_142 (Conv2D)             (None, 32, 32, 256)  16640       activation_130[0][0]             
    __________________________________________________________________________________________________
    batch_normalization_140 (BatchN (None, 32, 32, 256)  1024        conv2d_142[0][0]                 
    __________________________________________________________________________________________________
    add_42 (Add)                    (None, 32, 32, 256)  0           batch_normalization_140[0][0]    
                                                                     activation_128[0][0]             
    __________________________________________________________________________________________________
    activation_131 (Activation)     (None, 32, 32, 256)  0           add_42[0][0]                     
    __________________________________________________________________________________________________
    conv2d_143 (Conv2D)             (None, 16, 16, 128)  32896       activation_131[0][0]             
    __________________________________________________________________________________________________
    batch_normalization_141 (BatchN (None, 16, 16, 128)  512         conv2d_143[0][0]                 
    __________________________________________________________________________________________________
    activation_132 (Activation)     (None, 16, 16, 128)  0           batch_normalization_141[0][0]    
    __________________________________________________________________________________________________
    conv2d_144 (Conv2D)             (None, 16, 16, 128)  147584      activation_132[0][0]             
    __________________________________________________________________________________________________
    batch_normalization_142 (BatchN (None, 16, 16, 128)  512         conv2d_144[0][0]                 
    __________________________________________________________________________________________________
    activation_133 (Activation)     (None, 16, 16, 128)  0           batch_normalization_142[0][0]    
    __________________________________________________________________________________________________
    conv2d_145 (Conv2D)             (None, 16, 16, 512)  66048       activation_133[0][0]             
    __________________________________________________________________________________________________
    conv2d_146 (Conv2D)             (None, 16, 16, 512)  131584      activation_131[0][0]             
    __________________________________________________________________________________________________
    batch_normalization_143 (BatchN (None, 16, 16, 512)  2048        conv2d_145[0][0]                 
    __________________________________________________________________________________________________
    batch_normalization_144 (BatchN (None, 16, 16, 512)  2048        conv2d_146[0][0]                 
    __________________________________________________________________________________________________
    add_43 (Add)                    (None, 16, 16, 512)  0           batch_normalization_143[0][0]    
                                                                     batch_normalization_144[0][0]    
    __________________________________________________________________________________________________
    activation_134 (Activation)     (None, 16, 16, 512)  0           add_43[0][0]                     
    __________________________________________________________________________________________________
    conv2d_147 (Conv2D)             (None, 16, 16, 128)  65664       activation_134[0][0]             
    __________________________________________________________________________________________________
    batch_normalization_145 (BatchN (None, 16, 16, 128)  512         conv2d_147[0][0]                 
    __________________________________________________________________________________________________
    activation_135 (Activation)     (None, 16, 16, 128)  0           batch_normalization_145[0][0]    
    __________________________________________________________________________________________________
    conv2d_148 (Conv2D)             (None, 16, 16, 128)  147584      activation_135[0][0]             
    __________________________________________________________________________________________________
    batch_normalization_146 (BatchN (None, 16, 16, 128)  512         conv2d_148[0][0]                 
    __________________________________________________________________________________________________
    activation_136 (Activation)     (None, 16, 16, 128)  0           batch_normalization_146[0][0]    
    __________________________________________________________________________________________________
    conv2d_149 (Conv2D)             (None, 16, 16, 512)  66048       activation_136[0][0]             
    __________________________________________________________________________________________________
    batch_normalization_147 (BatchN (None, 16, 16, 512)  2048        conv2d_149[0][0]                 
    __________________________________________________________________________________________________
    add_44 (Add)                    (None, 16, 16, 512)  0           batch_normalization_147[0][0]    
                                                                     activation_134[0][0]             
    __________________________________________________________________________________________________
    activation_137 (Activation)     (None, 16, 16, 512)  0           add_44[0][0]                     
    __________________________________________________________________________________________________
    conv2d_150 (Conv2D)             (None, 16, 16, 128)  65664       activation_137[0][0]             
    __________________________________________________________________________________________________
    batch_normalization_148 (BatchN (None, 16, 16, 128)  512         conv2d_150[0][0]                 
    __________________________________________________________________________________________________
    activation_138 (Activation)     (None, 16, 16, 128)  0           batch_normalization_148[0][0]    
    __________________________________________________________________________________________________
    conv2d_151 (Conv2D)             (None, 16, 16, 128)  147584      activation_138[0][0]             
    __________________________________________________________________________________________________
    batch_normalization_149 (BatchN (None, 16, 16, 128)  512         conv2d_151[0][0]                 
    __________________________________________________________________________________________________
    activation_139 (Activation)     (None, 16, 16, 128)  0           batch_normalization_149[0][0]    
    __________________________________________________________________________________________________
    conv2d_152 (Conv2D)             (None, 16, 16, 512)  66048       activation_139[0][0]             
    __________________________________________________________________________________________________
    batch_normalization_150 (BatchN (None, 16, 16, 512)  2048        conv2d_152[0][0]                 
    __________________________________________________________________________________________________
    add_45 (Add)                    (None, 16, 16, 512)  0           batch_normalization_150[0][0]    
                                                                     activation_137[0][0]             
    __________________________________________________________________________________________________
    activation_140 (Activation)     (None, 16, 16, 512)  0           add_45[0][0]                     
    __________________________________________________________________________________________________
    conv2d_153 (Conv2D)             (None, 16, 16, 128)  65664       activation_140[0][0]             
    __________________________________________________________________________________________________
    batch_normalization_151 (BatchN (None, 16, 16, 128)  512         conv2d_153[0][0]                 
    __________________________________________________________________________________________________
    activation_141 (Activation)     (None, 16, 16, 128)  0           batch_normalization_151[0][0]    
    __________________________________________________________________________________________________
    conv2d_154 (Conv2D)             (None, 16, 16, 128)  147584      activation_141[0][0]             
    __________________________________________________________________________________________________
    batch_normalization_152 (BatchN (None, 16, 16, 128)  512         conv2d_154[0][0]                 
    __________________________________________________________________________________________________
    activation_142 (Activation)     (None, 16, 16, 128)  0           batch_normalization_152[0][0]    
    __________________________________________________________________________________________________
    conv2d_155 (Conv2D)             (None, 16, 16, 512)  66048       activation_142[0][0]             
    __________________________________________________________________________________________________
    batch_normalization_153 (BatchN (None, 16, 16, 512)  2048        conv2d_155[0][0]                 
    __________________________________________________________________________________________________
    add_46 (Add)                    (None, 16, 16, 512)  0           batch_normalization_153[0][0]    
                                                                     activation_140[0][0]             
    __________________________________________________________________________________________________
    activation_143 (Activation)     (None, 16, 16, 512)  0           add_46[0][0]                     
    __________________________________________________________________________________________________
    conv2d_156 (Conv2D)             (None, 16, 16, 128)  65664       activation_143[0][0]             
    __________________________________________________________________________________________________
    batch_normalization_154 (BatchN (None, 16, 16, 128)  512         conv2d_156[0][0]                 
    __________________________________________________________________________________________________
    activation_144 (Activation)     (None, 16, 16, 128)  0           batch_normalization_154[0][0]    
    __________________________________________________________________________________________________
    conv2d_157 (Conv2D)             (None, 16, 16, 128)  147584      activation_144[0][0]             
    __________________________________________________________________________________________________
    batch_normalization_155 (BatchN (None, 16, 16, 128)  512         conv2d_157[0][0]                 
    __________________________________________________________________________________________________
    activation_145 (Activation)     (None, 16, 16, 128)  0           batch_normalization_155[0][0]    
    __________________________________________________________________________________________________
    conv2d_158 (Conv2D)             (None, 16, 16, 512)  66048       activation_145[0][0]             
    __________________________________________________________________________________________________
    batch_normalization_156 (BatchN (None, 16, 16, 512)  2048        conv2d_158[0][0]                 
    __________________________________________________________________________________________________
    add_47 (Add)                    (None, 16, 16, 512)  0           batch_normalization_156[0][0]    
                                                                     activation_143[0][0]             
    __________________________________________________________________________________________________
    activation_146 (Activation)     (None, 16, 16, 512)  0           add_47[0][0]                     
    __________________________________________________________________________________________________
    conv2d_159 (Conv2D)             (None, 16, 16, 128)  65664       activation_146[0][0]             
    __________________________________________________________________________________________________
    batch_normalization_157 (BatchN (None, 16, 16, 128)  512         conv2d_159[0][0]                 
    __________________________________________________________________________________________________
    activation_147 (Activation)     (None, 16, 16, 128)  0           batch_normalization_157[0][0]    
    __________________________________________________________________________________________________
    conv2d_160 (Conv2D)             (None, 16, 16, 128)  147584      activation_147[0][0]             
    __________________________________________________________________________________________________
    batch_normalization_158 (BatchN (None, 16, 16, 128)  512         conv2d_160[0][0]                 
    __________________________________________________________________________________________________
    activation_148 (Activation)     (None, 16, 16, 128)  0           batch_normalization_158[0][0]    
    __________________________________________________________________________________________________
    conv2d_161 (Conv2D)             (None, 16, 16, 512)  66048       activation_148[0][0]             
    __________________________________________________________________________________________________
    batch_normalization_159 (BatchN (None, 16, 16, 512)  2048        conv2d_161[0][0]                 
    __________________________________________________________________________________________________
    add_48 (Add)                    (None, 16, 16, 512)  0           batch_normalization_159[0][0]    
                                                                     activation_146[0][0]             
    __________________________________________________________________________________________________
    activation_149 (Activation)     (None, 16, 16, 512)  0           add_48[0][0]                     
    __________________________________________________________________________________________________
    conv2d_162 (Conv2D)             (None, 8, 8, 256)    131328      activation_149[0][0]             
    __________________________________________________________________________________________________
    batch_normalization_160 (BatchN (None, 8, 8, 256)    1024        conv2d_162[0][0]                 
    __________________________________________________________________________________________________
    activation_150 (Activation)     (None, 8, 8, 256)    0           batch_normalization_160[0][0]    
    __________________________________________________________________________________________________
    conv2d_163 (Conv2D)             (None, 8, 8, 256)    590080      activation_150[0][0]             
    __________________________________________________________________________________________________
    batch_normalization_161 (BatchN (None, 8, 8, 256)    1024        conv2d_163[0][0]                 
    __________________________________________________________________________________________________
    activation_151 (Activation)     (None, 8, 8, 256)    0           batch_normalization_161[0][0]    
    __________________________________________________________________________________________________
    conv2d_164 (Conv2D)             (None, 8, 8, 1024)   263168      activation_151[0][0]             
    __________________________________________________________________________________________________
    conv2d_165 (Conv2D)             (None, 8, 8, 1024)   525312      activation_149[0][0]             
    __________________________________________________________________________________________________
    batch_normalization_162 (BatchN (None, 8, 8, 1024)   4096        conv2d_164[0][0]                 
    __________________________________________________________________________________________________
    batch_normalization_163 (BatchN (None, 8, 8, 1024)   4096        conv2d_165[0][0]                 
    __________________________________________________________________________________________________
    add_49 (Add)                    (None, 8, 8, 1024)   0           batch_normalization_162[0][0]    
                                                                     batch_normalization_163[0][0]    
    __________________________________________________________________________________________________
    activation_152 (Activation)     (None, 8, 8, 1024)   0           add_49[0][0]                     
    __________________________________________________________________________________________________
    conv2d_166 (Conv2D)             (None, 8, 8, 256)    262400      activation_152[0][0]             
    __________________________________________________________________________________________________
    batch_normalization_164 (BatchN (None, 8, 8, 256)    1024        conv2d_166[0][0]                 
    __________________________________________________________________________________________________
    activation_153 (Activation)     (None, 8, 8, 256)    0           batch_normalization_164[0][0]    
    __________________________________________________________________________________________________
    conv2d_167 (Conv2D)             (None, 8, 8, 256)    590080      activation_153[0][0]             
    __________________________________________________________________________________________________
    batch_normalization_165 (BatchN (None, 8, 8, 256)    1024        conv2d_167[0][0]                 
    __________________________________________________________________________________________________
    activation_154 (Activation)     (None, 8, 8, 256)    0           batch_normalization_165[0][0]    
    __________________________________________________________________________________________________
    conv2d_168 (Conv2D)             (None, 8, 8, 1024)   263168      activation_154[0][0]             
    __________________________________________________________________________________________________
    batch_normalization_166 (BatchN (None, 8, 8, 1024)   4096        conv2d_168[0][0]                 
    __________________________________________________________________________________________________
    add_50 (Add)                    (None, 8, 8, 1024)   0           batch_normalization_166[0][0]    
                                                                     activation_152[0][0]             
    __________________________________________________________________________________________________
    activation_155 (Activation)     (None, 8, 8, 1024)   0           add_50[0][0]                     
    __________________________________________________________________________________________________
    conv2d_169 (Conv2D)             (None, 8, 8, 256)    262400      activation_155[0][0]             
    __________________________________________________________________________________________________
    batch_normalization_167 (BatchN (None, 8, 8, 256)    1024        conv2d_169[0][0]                 
    __________________________________________________________________________________________________
    activation_156 (Activation)     (None, 8, 8, 256)    0           batch_normalization_167[0][0]    
    __________________________________________________________________________________________________
    conv2d_170 (Conv2D)             (None, 8, 8, 256)    590080      activation_156[0][0]             
    __________________________________________________________________________________________________
    batch_normalization_168 (BatchN (None, 8, 8, 256)    1024        conv2d_170[0][0]                 
    __________________________________________________________________________________________________
    activation_157 (Activation)     (None, 8, 8, 256)    0           batch_normalization_168[0][0]    
    __________________________________________________________________________________________________
    conv2d_171 (Conv2D)             (None, 8, 8, 1024)   263168      activation_157[0][0]             
    __________________________________________________________________________________________________
    batch_normalization_169 (BatchN (None, 8, 8, 1024)   4096        conv2d_171[0][0]                 
    __________________________________________________________________________________________________
    add_51 (Add)                    (None, 8, 8, 1024)   0           batch_normalization_169[0][0]    
                                                                     activation_155[0][0]             
    __________________________________________________________________________________________________
    activation_158 (Activation)     (None, 8, 8, 1024)   0           add_51[0][0]                     
    __________________________________________________________________________________________________
    conv2d_172 (Conv2D)             (None, 8, 8, 256)    262400      activation_158[0][0]             
    __________________________________________________________________________________________________
    batch_normalization_170 (BatchN (None, 8, 8, 256)    1024        conv2d_172[0][0]                 
    __________________________________________________________________________________________________
    activation_159 (Activation)     (None, 8, 8, 256)    0           batch_normalization_170[0][0]    
    __________________________________________________________________________________________________
    conv2d_173 (Conv2D)             (None, 8, 8, 256)    590080      activation_159[0][0]             
    __________________________________________________________________________________________________
    batch_normalization_171 (BatchN (None, 8, 8, 256)    1024        conv2d_173[0][0]                 
    __________________________________________________________________________________________________
    activation_160 (Activation)     (None, 8, 8, 256)    0           batch_normalization_171[0][0]    
    __________________________________________________________________________________________________
    conv2d_174 (Conv2D)             (None, 8, 8, 1024)   263168      activation_160[0][0]             
    __________________________________________________________________________________________________
    batch_normalization_172 (BatchN (None, 8, 8, 1024)   4096        conv2d_174[0][0]                 
    __________________________________________________________________________________________________
    add_52 (Add)                    (None, 8, 8, 1024)   0           batch_normalization_172[0][0]    
                                                                     activation_158[0][0]             
    __________________________________________________________________________________________________
    activation_161 (Activation)     (None, 8, 8, 1024)   0           add_52[0][0]                     
    __________________________________________________________________________________________________
    conv2d_175 (Conv2D)             (None, 8, 8, 256)    2359552     activation_161[0][0]             
    __________________________________________________________________________________________________
    activation_162 (Activation)     (None, 8, 8, 256)    0           conv2d_175[0][0]                 
    __________________________________________________________________________________________________
    conv2d_176 (Conv2D)             (None, 8, 8, 18)     4626        activation_162[0][0]             
    __________________________________________________________________________________________________
    lambda_2 (Lambda)               (None, None, 2)      0           conv2d_176[0][0]                 
    __________________________________________________________________________________________________
    conv2d_177 (Conv2D)             (None, 8, 8, 36)     9252        activation_162[0][0]             
    __________________________________________________________________________________________________
    activation_163 (Activation)     (None, None, 2)      0           lambda_2[0][0]                   
    __________________________________________________________________________________________________
    activation_165 (Activation)     (None, 8, 8, 36)     0           conv2d_177[0][0]                 
    __________________________________________________________________________________________________
    activation_164 (Activation)     (None, None, 2)      0           activation_163[0][0]             
    __________________________________________________________________________________________________
    lambda_3 (Lambda)               (None, None, 4)      0           activation_165[0][0]             
    ==================================================================================================
    Total params: 9,276,086
    Trainable params: 9,248,566
    Non-trainable params: 27,520
    __________________________________________________________________________________________________



```python
plot_model(rpn_model,to_file="images/rpn_model.png",show_shapes=True)
```

![rpn_model.png](images/rpn_model.png)
